# -*- coding: utf-8 -*-
"""Data Pipelines with Neo4j-Simeon Omeda.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NdDKKVQJjnJQ66eNXt7mx-mDvB3-4tqU

#Data Pipelines with Neo4j-Simeon Omeda.ipynb

**Background Information**

You have been hired by a telecommunications company that wants to optimize their business
processes. They have a Neo4j graph database that contains information about their customers,
their subscriptions, and the services they are using. However, they also want to store this data
in a more traditional relational database to allow for easier querying and analysis. They have
asked you to create a data pipeline that extracts data from their Neo4j database, transforms it
using pandas, and loads it into a Postgres database.

**Guidelines**

***1. Extracting data from Neo4j:***

To extract data from the Neo4j database, you will need to use the Neo4j Python driver.
You must authenticate with the database and write a Cypher query to extract the
necessary data. The fields that you should extract from the database include the
following:

● Customer ID

● Subscription ID

● Service ID

● Start date of subscription

● End date of subscription

● Price of subscription

***2. Transforming data using Pandas:***

Once you have extracted the data from Neo4j, you must transform it using Pandas. You
should create a Pandas DataFrame from the extracted data and perform any necessary
data cleaning and manipulation. For example, you may need to convert date fields from
strings to datetime objects and remove null values.

***3. Loading data into Postgres:***

Finally, you must load the transformed data into a Postgres database. You should create
a new table in the Postgres database with the following fields:

● Customer ID (integer)

● Subscription ID (integer)

● Service ID (integer)

● Start date of subscription (date)

● End date of subscription (date)

● Price of subscription (float)

You should then use the psycopg2 Python library to connect to the Postgres database
and write a function to insert the transformed data into the new table.

*You can find the file to start working on this project here [link].*

**Deliverables**

We will be expected to deliver a GitHub repository with the following:

● A Python file containing extract, transform, and load functions.

● A README file explaining how to set up and run the data pipeline, explaining the data
schema and the transformations performed on the data.

**Pre-requisites**
"""

# importing neo4j drive
!pip install neo4j

# Import required libraries
from neo4j import GraphDatabase
import pandas as pd
import psycopg2
from datetime import datetime

"""**1. Extracting data from Neo4j:**"""

# Populating the data to use in the neo4j database
from neo4j import GraphDatabase

uri = "neo4j+s://0d9b2cb0.databases.neo4j.io"
username = "neo4j"
password = "xjqTLdbpxREFLPp8QKpVTQA8_Vsr5B34m4AsAGSuc48"

driver = GraphDatabase.driver(uri, auth=(username, password))

def create_telecom(tx, Customer_ID, Subscription_ID, Start_date_of_subscription, End_date_of_subscription, Price_of_subscription):
    tx.run("MERGE (t:Telecom {Customer_ID: $Customer_ID, Subscription_ID: $Subscription_ID, Start_date_of_subscription: $Start_date_of_subscription, End_date_of_subscription: $End_date_of_subscription, Price_of_subscription: $Price_of_subscription})", 
           Customer_ID=Customer_ID, Subscription_ID=Subscription_ID,  Start_date_of_subscription=Start_date_of_subscription, End_date_of_subscription=End_date_of_subscription, Price_of_subscription=Price_of_subscription)



with driver.session() as session:
    # create some sample data
    session.execute_write(create_telecom, "1234", "H177","2020-01-01", "2020-10-01", 25)
    session.execute_write(create_telecom, "2345", "T199","2019-06-01" ,"2019-10-01",30)
    session.execute_write(create_telecom, "3456", "S503","2018-03-01","2018-10-01" ,28)
    session.execute_write(create_telecom, "4567", "D999","2022-02-01","2022-10-01" ,27)
driver.close()

with driver.session() as session:
    result = session.run("RETURN 1")
    for record in result:
        print(record)

# # Define Neo4j query to extract data
# neo4j_query = 

neo4j_query = "MERGE (c:customer_data) RETURN c"

# Define function to extract data from Neo4j and return a Pandas DataFrame
# def extract_data():
#     # Connect to Neo4j


from neo4j import GraphDatabase

uri = "neo4j+s://0d9b2cb0.databases.neo4j.io"
username = "neo4j"
password = "xjqTLdbpxREFLPp8QKpVTQA8_Vsr5B34m4AsAGSuc48"

driver = GraphDatabase.driver(uri, auth=(username, password))

def extract_data(tx):
    # Extract all telecom nodes with their properties 
    results = tx.run("MERGE (t:Telecom) RETURN t.Customer_ID, t.Subscription_ID, t.Start_date_of_subscription, t.End_date_of_subscription, t.Price_of_subscription")
    return pd.DataFrame([r.values() for r in results], columns=["Customer_ID", "Subscription_ID", "Start_date_of_subscription", "End_date_of_subscription", "Price_of_subscription"])

"""**2. Transforming data using Pandas:**

"""

def transform_data(df):
    # Create a new DataFrame to hold transformed data
    transformed_df = pd.DataFrame(columns=["Customer_ID", "Subscription_ID", "Start_date_of_subscription", "End_date_of_subscription", "Price_of_subscription"])

    # Group by person names and sum the friendship strengths
    group = df.groupby(["Customer_ID"], as_index=False)["Price_of_subscription"].sum()
    
    return transformed_df

"""convert date fields from
strings to datetime objects and remove null values
"""

try:
        
        df["Start_date_of_subscription"] = pd.to_datetime(df["Start_date_of_subscription"],format='%d-%m-%Y')
        df["End_date_of_subscription"] = pd.to_datetime(df["End_date_of_subscription"],format='%d-%m-%Y')

        # Remove null values
        df = df.dropna()
    
    except Exception as e:
        err = "Transform() error - "+str(e)
        logging.debug(err)
     
    return df

"""**3. Loading data into Postgres:**

"""

# Postgres Database Information
pg_host = '35.196.132.175'
pg_database = 'someda_db'
pg_user = 'someda'
pg_password = '@someda123'

# Define function to load data into Postgres
def load_data(transformed_df):

    # Connect to Postgres
    try:
        
        conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)
        # Create table if it doesn't exist
        with conn.cursor() as cursor:
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS telecom_data (
                customer_id INTEGER,
                subscription_id INTEGER,
                service_id VARCHAR,
                start_date DATE,
                end_date DATE,
                price FLOAT
            )
            """)
      
            for _, row in transformed_df.iterrows():
                cursor.execute("INSERT INTO telecom_data (customer_id, subscription_id, service_id, start_date, end_date, price) VALUES (%s, %s, %s, %s, %s, %s)",
                       (row['customer_id'], row['subscription_id'], row['service_id'], row['start_date'], row['end_date'], row['subscription_price']))


        conn.commit()


        # Close the cursor and connection
        cursor.close()
        conn.close()
    
    except Exception as e:
        err = "Load() error - "+str(e)
        logging.debug(err)

# Define main function
def main():
    # Extract data from Neo4j
    df = extract_data(neo4j_uri, neo4j_user, neo4j_password, neo4j_query)
    
    # Transform data using Pandas
    df = transform_data(df)
    
    # Load data into Postgres
    load_data(df)

# Call main function
if __name__ == "__main__":
    main()